var = {
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from nltk.corpus import movie_reviews"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "all_words = movie_reviews.words()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'words' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-24-e9f98197017b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfreq_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFreqDist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m: name 'words' is not defined"
                    ]
                }
            ],
            "source": [
                "freq_dist = nltk.FreqDist(words)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "freq_dist.most_common(60)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": [
                "import nltk.classify.util\n",
                "from nltk.classify import NaiveBayesClassifier\n",
                "from nltk.corpus import movie_reviews\n",
                "from nltk.corpus import stopwords\n",
                "from nltk.tokenize import word_tokenize\n",
                "from nltk.corpus import wordnet"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "ename": "SyntaxError",
                    "evalue": "invalid syntax (<ipython-input-19-1a00918a2942>, line 3)",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-1a00918a2942>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    my_dict = dict([(word, True) if word in useful_words])\u001b[0m\n\u001b[0m                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
                    ]
                }
            ],
            "source": [
                "def create_word_features(words):\n",
                "    useful_words = [word for word in words if word not in stopwords.words('english')]\n",
                "    my_dict = dict([(word, True) if word in useful_words])\n",
                "    return my_dict"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "import nltk.classify.util\n",
                "from nltk.classify import NaiveBayesClassifier\n",
                "from nltk.corpus import movie_reviews\n",
                "from nltk.corpus import stopwords\n",
                "from nltk.tokenize import word_tokenize"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "ename": "SyntaxError",
                    "evalue": "invalid syntax (<ipython-input-21-1a00918a2942>, line 3)",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-1a00918a2942>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    my_dict = dict([(word, True) if word in useful_words])\u001b[0m\n\u001b[0m                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
                    ]
                }
            ],
            "source": [
                "def create_word_features(words):\n",
                "    useful_words = [word for word in words if word not in stopwords.words('english')]\n",
                "    my_dict = dict([(word, True) if word in useful_words])\n",
                "    return my_dict"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "import nltk.classify.util\n",
                "from nltk.classify import NaiveBayesClassifier\n",
                "from nltk.corpus import movie_reviews\n",
                "from nltk.corpus import stopwords\n",
                "from nltk.tokenize import word_tokenize"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "ename": "SyntaxError",
                    "evalue": "invalid syntax (<ipython-input-26-1a00918a2942>, line 3)",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-1a00918a2942>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    my_dict = dict([(word, True) if word in useful_words])\u001b[0m\n\u001b[0m                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
                    ]
                }
            ],
            "source": [
                "def create_word_features(words):\n",
                "    useful_words = [word for word in words if word not in stopwords.words('english')]\n",
                "    my_dict = dict([(word, True) if word in useful_words])\n",
                "    return my_dict"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [],
            "source": [
                "import nltk.classify.util\n",
                "from nltk.classify import NaiveBayesClassifier\n",
                "from nltk.corpus import movie_reviews\n",
                "from nltk.corpus import stopwords\n",
                "from nltk.tokenize import word_tokenize"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 66,
            "metadata": {},
            "outputs": [
                {
                    "ename": "SyntaxError",
                    "evalue": "invalid syntax (<ipython-input-66-1a00918a2942>, line 3)",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-66-1a00918a2942>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    my_dict = dict([(word, True) if word in useful_words])\u001b[0m\n\u001b[0m                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
                    ]
                }
            ],
            "source": [
                "def create_word_features(words):\n",
                "    useful_words = [word for word in words if word not in stopwords.words('english')]\n",
                "    my_dict = dict([(word, True) if word in useful_words])\n",
                "    return my_dict"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "metadata": {},
            "outputs": [],
            "source": [
                "import nltk.classify.util\n",
                "from nltk.classify import NaiveBayesClassifier\n",
                "from nltk.corpus import movie_reviews\n",
                "from nltk.corpus import stopwords\n",
                "from nltk.tokenize import word_tokenize"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 67,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'quick': True, 'fox': True, 'brown': True}"
                        ]
                    },
                    "execution_count": 67,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#dit is het eerste deel van hoe je een woordenboek (dict in deze ) maakt van losse woorden, je moet er voor zorgen dat er true achter de woorden staat want anders werkt de Naive Bayes classifier niet.\n",
                "def create_word_features(words):\n",
                "    useful_words = [word for word in words if word not in stopwords.words(\"english\")]\n",
                "    my_dict = dict([(word, True) for word in useful_words])\n",
                "    return my_dict\n",
                "create_word_features([\"the\",\"a\",\"quick\",\"fox\",\"quick\",\"brown\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 77,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1000\n"
                    ]
                }
            ],
            "source": [
                "#hier zorgen we ervoor dat we de negatieve reviews splitsen in woorden i.p.v. documenten, het enige nadeel is dat het exreem veel reviews zijn en daardoor het lang duurt voordat er een output is.\n",
                "#vandaar dat print(neg_reviews) tussen een # staat en de computer dat dus niet doet.\n",
                "neg_reviews =[]\n",
                "for fileid in movie_reviews.fileids('neg'):\n",
                "    words = movie_reviews.words(fileid)\n",
                "    neg_reviews.append((create_word_features(words), \"negative\"))\n",
                "    \n",
                "#print(neg_reviews)\n",
                "print(len(neg_reviews))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 74,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1000\n"
                    ]
                }
            ],
            "source": [
                "#hier gebeurt hetzelfde als hierboven met de negatieve reviews maar dan met de positieve reviews\n",
                "pos_reviews =[]\n",
                "for fileid in movie_reviews.fileids('pos'):\n",
                "    words = movie_reviews.words(fileid)\n",
                "    pos_reviews.append((create_word_features(words), \"positive\"))\n",
                "\n",
                "#print(pos_reviews[0])\n",
                "print(len(pos_reviews))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 76,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1500 500\n"
                    ]
                }
            ],
            "source": [
                "#hier kijken we hoeveel reviews we willen als training voor machine learning en hoeveel als echt proefje om te kijken of machine learning werkt\n",
                "train_set = neg_reviews[:750] + pos_reviews[:750]\n",
                "test_set = neg_reviews[750:] + pos_reviews[750:]\n",
                "print(len(train_set), len (test_set))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
